<!DOCTYPE html>

<title>October 10, 2022 | uncultu.red</title>
<link href="/style.css" rel="stylesheet">
<meta name="viewport" content="width=device-width">

<p>
  I promise Iâ€™ll stop talking about filesystems soon, just want to pull at this thread a little longer.

<p>
  So it sounds like itâ€™s impossible to build the perfect filesystem abstraction thatâ€™s interoperable with existing applications. I guess I can live with that, I hate all existing applications anyway ðŸ˜¤. But for new stuff, it might be possible to build some kind of generic interface for managing and querying file metadata while hiding all other storage details. My goal for such a filesystem would be to manage metadata well enough that it can effectively assume that role for all apps built atop it; any time I need to browse, search, or edit metadata, the only tool Iâ€™d need to reach for is the file browser. All I then really need apps for is for transformations of the files themselves, and my data remains organized to my liking even after I decide to stop using a given app. For tools that are pretty metadata-heavy (music players, photo album viewers, note organizers, task management software, etc.), the app can offload a lot of heavy lifting and state management to the filesystem, which is of benefit to the user.

<p>
  I foresee some problems in designing such a thing. The first is that the interface with the storage layer (likely a traditional filesystem) needs to be exceedingly robust. If different implementations (or different versions of the same implementation) are interacting with the same underlying storage, they need to coordinate their access and manipulate data in an interoperable way. An easy circumvention could be to ensure all access to the filesystem is delegated through the same implementation, by using a daemon or server of some kind. A daemon requires that all file access happens via inter-process communication, which presents a rather large performance problem. A daemon also doesnâ€™t solve the problem if the underlying filesystem is distributed, because you could have multiple daemons running on multiple machines accessing the same filesystem. A server could allow for distributed access through a single implementation, but would require your apps to work online-only and presents an even worse performance problem. No, I think it would need to be a library that every application consumes, meaning Iâ€™m probably stuck writing it in C if I want interoperability unless the interface is simple enough (and standardized well enough to prevent idiosyncrasies) that each language can have a native implementation.

<p>
  If the abstraction is intended to manage all metadata, then that includes examples of intrinsic metadata that is encoded within a file (like Exif or ID3). This implies it must be file format-aware, and know how to read and write as many different kinds of metadata encodings as possible. This isnâ€™t trivialâ€”just look at how complicated <a href="https://en.wikipedia.org/wiki/ExifTool">ExifTool</a> is. Managing metadata also implies exclusive access to said metadataâ€¦ but if it is present in the file itself, itâ€™s not really possible to prevent an application from reading or writing to it. As querying in-file metadata can be resource-intensive, I'd want a cache, but the only way to maintain an up-to-date cache is to trap every <code>write()</code> call and keep track of metadata changes (which precludes any kind of <code>mmap()</code>-style API). I think the better solution is just to strip and parse metadata from files as they're copied in, which immediately solves the querying performance and source-of-truth problems. It also means I could delegate all this format-aware metadata parsing to a layer above the filesystem abstractionâ€”like the file browser where things are dragged and dropped intoâ€”keeping the abstraction much simpler.

<p>
  The KeePass anecdote and your point about versioning and Git-backed services got me thinking; what does building on top of Git really do for your app? In a way, using a central Git server functions pretty similarly to a synchronizing distributed filesystem (is that the right term to use?) like Dropbox, except that synchronization happens more discretely. It doesn't prevent conflicts, but does give you a sane way to resolve them. And as you say, because the conflict happens at the point of synchronization, you're forced to deal with it promptly. But the resolution format only works for line-based content, so most file formats used by everyday applications can't benefit from a universal conflict resolution tool. Dropbox just dumps both copies of the conflicted file into a folder and tells you to <a href="https://help.dropbox.com/organize/conflicted-copy#:~:text=What%20do%20I%20do%20now?">figure it out</a>, and to please use an online app to prevent conflicts.

<p>
  So does this mean that this whole filesystem exercise is futile and self-hosted services are the only remaining avenue for data freedom? I'm not sure, perhaps. I don't think there is anything fundamentally different about service-mediated access to data and multiple processes accessing the same files on a filesystem, only that the local processes need to be cleverer in how they coordinate access. That's fine for a local filesystem, but apparently not so fine for a <a href="https://www.sqlite.org/howtocorrupt.html#_filesystems_with_broken_or_missing_lock_implementations">networked filesystem</a>, and definitely not fine for a synchronized filesystem. So that might be the coup de grace for my idea of building a filesystem abstraction that works seamlessly atop Dropbox. If I wanted an abstraction that worked in a distributed manner, I think I'd need to build my own synchronizing file server to serve it, which really undermines its portability.
