<!DOCTYPE html>

<title>September 26, 2025 | uncultu.red</title>
<link href="/style.css" rel="stylesheet">
<meta name="viewport" content="width=device-width">

<p>
  Upspin divorces file storage from fileystem structure by defining two server interfaces: the directory server and the store server. The two servers are independent and do not directly communicate; they are connected only by the client which writes blocks to the store server and then tells the directory server about them. Concretely, when a user wants to write to a file they first upload the (encrypted) contents in blocks to the store server, assembles the returned block references into a signed directory entry (together with the desired pathname and some other metadata) and sends these to the directory server. Each block reference must be paired with the URL of the store server, or a reader of the dentry wouldn't know where to request the blocks. Store servers thus don't have a concept of a file, they simply persist and retrieve blocks with an arbitrary reference.
<p>
  Implied is that a user can spread their filesystem over multiple store servers; technically they can even spread the blocks of a single file across servers. If another user is granted write-access to a file, that user will use their own configured store server to write blocks to, meaning their contributions to the file are likely to be written to storage that the owner of the file does not control. This is because the directory server cannot communicate access control rules to the owner's preferred store server, meaning the store server will reject attempts to write blocks from unknown users. The result is that when deciding whether to grant another write-access to a folder within your filesystem you should consider not only whether you can trust their material contributions, but also whether the reliability of their personal Upspin infrastructure might impact the availability of (parts of) your filesystem.
<p>
  An important aspect of the store server's contract is that block contents are immutable. Directory entries maintain the hash of each block alongside the reference, and the whole entry is signed by the last writer, meaning a reader of a file will immediately notice if a block returned by a store server is different than what the author of that block has claimed to have originally sent. Immutability gives Upspin copy-on-write characteristics; editing a file involves uploading new blocks and updating the references in the directory entry. A file can be copied by copying the block references into a new directory entry, and won't be affected if the original updates its references. And so it is important that file deletion isn't followed up with immediate deletion of its blocks, unless the client is certain there are no other entries referencing them. Guaranteeing that a block is unreferenced (and thus eligible for garbage collection) is difficult: a file can be copied by any user it is shared with, where it can in turn be shared with and copied by others, distributing the block references broadly without knowledge of the original file owner.
<p>
  To mitigate conflicting writes, directory entries contain a monotonically-increasing sequence number. Write operations pass along the sequence and will be rejected if it is out-of-date. The sequence number is global to a user's tree, and writing to a file sets the file's sequence along with that of all parent directories to the highest sequence plus one. As such a directory always has the sequence of the most recently written file within it. The directory server maintains a log of every put and delete operation (each of which increment the tree's sequence) and can be asked for all events for a given subtree starting from a particular sequence. This can be useful to synchronize caching servers.
<p>
  In the reference implementation of the directory server, the state of a tree is also stored in the store server. This sounds like it contradicts what I said earlier about the two servers not communicating, but the store server used by the directory server might be completely different from the one used by its users. It's not a part of the Upspin protocol, but <a href="https://github.com/upspin/upspin/issues/52">is something users might rely on</a>. Each directory in the tree contains blocks just like a regular file, where the contents are the serialized directory entries of its children. Since block references contain a hash of the block's contents, in effect this builds a Merkle tree which can be navigated and verified by grabbing a user's root directory entry. As each directory entry fully captures the state of the subtree below it, atomic snapshots of any subtree (or the whole filesystem) can be made by simply copying the block references of a given directory. Snapshots are configured daily by default, to a suffixed "+snapshot" username with a /year/month/day/ hierarchy of snapshots.
<p>
  Block sizes are set by the client and can change per-block. This means that a client choosing an inappropriately small block size for a large file could saddle the directory server with a lot of overhead. If the average block reference encoded in a directory entry needs 80 bytes (a conservative estimate; <a href="https://pkg.go.dev/upspin.io/upspin#DirBlock">each contains</a> a URL for a store server, a unique identifier known to that server, a 64-bit size, a 64-bit offset, and a 256-bit hash of the ciphertext), a 1 KiB block size would mean directory entries roughly 8% of the file size. Upspin's default block size is 1 MiB, meaning a much more reasonable ~0.01% overhead.
<p>
  This provokes a discussion on the optimal block size for a distributed filesystem. Smaller block sizes can reduce the amount of data that needs to be re-transferred when a transfer fails (imagine uploading a 10 GiB file on an unreliable network: if the bandwidth should allow it to complete in 10 minutes but the connection drops ~once per minute, 1 KiB blocks would mean 10 KiB needs to be retried but 1 GiB blocks might never see the transfer complete), but as mentioned incurs extra storage overhead. One would expect that small block sizes could also reduce data transfer when editing a file, but in Upspin every write generates a new encryption key, meaning all blocks need to be re-encrypted and re-uploaded. This is to ensure no portion of the keystream is ever reused for a given file, as Upspin uses the AES cipher in counter mode to encrypt files. An exception could be made for writes that only append to a file, but this was <a href="https://github.com/upspin/upspin/blob/334f107fe3d98225d7adfbb35b74e066fbca9875/pack/ee/ee.go#L96">never implemented</a>. Likely there could be some optimization made to allow for per-block replacement (perhaps by extending the block reference to include the sequence number it was written for, and placing it in the high-bits of the initialization vector for that block?), but this would only help for in-place edits that don't cause any shift in adjacent bytes. Perhaps the decision of a new key per write is to protect against users who have lost access to a file, but may have kept the key. In any case, large files that see frequent edits cause a large amount of churn in Upspin (e.g. storing a virtual machine disk image could quickly overload client and server absent heavy rate-limiting).
<p>
  Conventional wisdom might say that the optimal block size is dependent on file size: big files should use bigger block sizes. This is how <code>rsync</code> <a href="https://unix.stackexchange.com/a/587783">apparently works</a>, but <code>rsync</code> only needs to maintain block references for the duration of a transfer, so the overhead is of minimal consequence. In Upspin where the unit of transfer is equal to the unit of storage, the ideals for transfer and storage efficiency are in opposition, and 1 MiB seems like a reasonable compromise. But it does beg the question: why can't the store server use blocks only during transfer, and persist entire files with a single reference?
